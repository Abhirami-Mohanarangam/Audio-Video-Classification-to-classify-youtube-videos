{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MAVOIX.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l8yF4KO6xB_7"
      },
      "source": [
        "\n",
        "# **AUDIO VIDEO CLASSIFICATION** "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kuhwz4tkxaQC"
      },
      "source": [
        "# *Install the required packages*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOIQ_3_PuszV"
      },
      "source": [
        "!pip install transformers\n",
        "!pip install SpeechRecognition\n",
        "!pip install pydub\n",
        "!pip install moviepy\n",
        "!pip install pafy\n",
        "!pip install youtube_dl\n",
        "!pip install youtube_transcript_api\n",
        "!pip install googletrans\n",
        "!pip install langdetect"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mw4RNoOLxoqd"
      },
      "source": [
        "# *Import the the required packages*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gUivHwLbHWmq"
      },
      "source": [
        "### Building the deep learning model\n",
        "from tensorflow.keras import models, layers, preprocessing\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "#from tensorflow.keras import optimizers, losses, activations, models\n",
        "from tensorflow.keras.layers import Conv2D, Dense, Input, Dropout, MaxPooling2D, GlobalAveragePooling1D, GlobalAveragePooling2D\n",
        "\n",
        "### Image classification\n",
        "from tensorflow.keras import applications\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "\n",
        "### Text Classification\n",
        "from transformers import TFBertModel,  BertConfig, BertTokenizerFast\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from googletrans import Translator\n",
        "import joblib\n",
        "\n",
        "### Audio processing and speech recognition\n",
        "import speech_recognition as sr \n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "import moviepy.editor as mp\n",
        "from youtube_transcript_api import YouTubeTranscriptApi\n",
        "from langdetect import detect\n",
        "\n",
        "### Text processing and other packages\n",
        "import nltk \n",
        "import re\n",
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import pafy\n",
        "\n",
        "nltk.download('stopwords')\n",
        "nltk.download('wordnet')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5veHd_Bwx-kk"
      },
      "source": [
        "# *Downloading videos from Youtube*\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TbviK7B_xtMa"
      },
      "source": [
        "def download_video(url, path, name):\n",
        "    video=pafy.new(url)\n",
        "    \n",
        "    ### get the best video\n",
        "    best_video=video.getbest()\n",
        "    best_video.download(filepath = path + '/' + name + '.mp4')\n",
        "    \n",
        "    #os.rename(path + '/' + video.title + '.mp4', path + '/' + name + '.mp4')\n",
        "\n",
        "    ### If available the video details are retrieved\n",
        "    meta = {\n",
        "        \"title\": str(video.title),\n",
        "        \"author\": str(video.author),\n",
        "        \"duration\": str(video.duration),\n",
        "        \"resulotion\": str(best_video),\n",
        "    }\n",
        "    return meta\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFD8Pa4XzpnM"
      },
      "source": [
        "# *Downloading subtitles if available or extracting audio from video and speech recognition*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vlBkyUcyzocu"
      },
      "source": [
        "### Function to get subtitles of the video from youtube\n",
        "def video_subs(url):\n",
        "    \n",
        "    ### Check and get auto generated youtube subtitles if available \n",
        "    try:\n",
        "        srt = YouTubeTranscriptApi.get_transcript(url)\n",
        "        text = [i['text'] for i in srt ]\n",
        "        text = ('. '.join(text))\n",
        "    except Exception as e:\n",
        "        text = \"Error\"\n",
        "    return text\n",
        "\n",
        "### Speech recognition\n",
        "def audio_to_text(path, name):\n",
        "    \n",
        "    r = sr.Recognizer()\n",
        "    \n",
        "    ### Extract audio from video and store as '.wav'\n",
        "    temp_aud = mp.VideoFileClip(path + '/' + name + '.mp4')  \n",
        "    temp_aud.audio.write_audiofile(path + '/' + name + '.wav')\n",
        "    \n",
        "    ### Split the audio along the silent parts\n",
        "    audio_file = AudioSegment.from_wav(path + '/' + name + '.wav')  \n",
        "    chunks = split_on_silence(audio_file,\n",
        "        min_silence_len = 500,\n",
        "        silence_thresh = audio_file.dBFS-13,\n",
        "        keep_silence=500,\n",
        "    )\n",
        "\n",
        "    folder_name = \"chunks\"\n",
        "\n",
        "    ### Create a directory to store the audio chunks\n",
        "    if not os.path.isdir(folder_name):\n",
        "        os.mkdir(folder_name)\n",
        "    whole_text = \"\"\n",
        "\n",
        "    ### Process each chunk \n",
        "    for i, audio_chunk in enumerate(chunks, start=1):\n",
        "\n",
        "        chunk_filename = os.path.join(folder_name, f\"chunk{i}.wav\")\n",
        "        audio_chunk.export(chunk_filename, format=\"wav\")\n",
        "        ### Recognize the chunk\n",
        "        with sr.AudioFile(chunk_filename) as source:\n",
        "            audio_listened = r.record(source)\n",
        "            ### Try converting it to text\n",
        "            try:\n",
        "                text = r.recognize_google(audio_listened)\n",
        "            except sr.UnknownValueError as e:\n",
        "                e = \" \"\n",
        "            else:\n",
        "                text = f\"{text.capitalize()}. \"\n",
        "                whole_text += text\n",
        "    os.remove(path + '/chunks')\n",
        "    return whole_text\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fdpQLdf122w"
      },
      "source": [
        "# *Generate the initial data of the video(Audio and video details)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytAxFOWF1alY"
      },
      "source": [
        "### Data of the video consisitng of audio text and other details if available\n",
        "def generate_min_data(path, url, name):\n",
        "    \n",
        "    ### Download the video\n",
        "    data = download_video(url, path, name)\n",
        "    \n",
        "    ### Get the subtitles if available\n",
        "    subs = video_subs(url[(url.find('=')) + 1:])\n",
        "    if(subs == \"Error\"):\n",
        "        ### If not use speech recognition\n",
        "        audio_text = audio_to_text(path, name)\n",
        "    else:\n",
        "        audio_text = subs\n",
        "    data[\"audio\"] = audio_text\n",
        "    if(audio_text != \"\"):\n",
        "        data[\"language\"] = detect(audio_text)\n",
        "    ### Write the data in a file\n",
        "    with open(path + '/' + name + '.txt', 'w') as json_file:\n",
        "        json.dump(data,json_file)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ccQGIqGx2Nea"
      },
      "source": [
        "# *Convert Videos to frames and store under the name of the video*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCqebTgj2LNA"
      },
      "source": [
        "### Function to convert video into frames\n",
        "def video_to_frames(video_path, frame_path, name, folder_name, frame_rate): \n",
        "      \n",
        "    vid = cv2.VideoCapture(video_path + '/' + name +  \".mp4\") \n",
        "    frame_num = frame_rate\n",
        "    ### Variable to check whether frames were extracted \n",
        "    success = True\n",
        "    \n",
        "    #frames = []\n",
        "    if(os.path.exists(frame_path + '/' + folder_name) == False):\n",
        "        os.mkdir(frame_path + '/' + folder_name)\n",
        "    while success:\n",
        "        success, frame = vid.read()\n",
        "        if(success != True):\n",
        "          break \n",
        "        if(frame_num % frame_rate == 0):\n",
        "            cv2.imwrite(frame_path + '/' + folder_name + '/' + name + '_' + str(frame_num) + \".jpg\", frame)\n",
        "        frame_num += 1\n",
        "    print(\"Done\")         \n",
        "    #return frames        \n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qDtQHIPdXzFm"
      },
      "source": [
        "# *Image data generator*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BUsVadK9X-2q"
      },
      "source": [
        "def generate_data(frame_rate, path, row = 360, column = 360):\n",
        "\n",
        "  data_gen = ImageDataGenerator(preprocessing_function = preprocess_input)\n",
        "  data_gen = data_gen.flow_from_directory( path, target_size=(row, column), batch_size = frame_rate)\n",
        "\n",
        "  return data_gen"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mP03HV7XMjk"
      },
      "source": [
        "# *Fine tune the InceptionV3 model for image classsification*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h9iEk5tRXX5w"
      },
      "source": [
        "def image_model(row, column, n_class):\n",
        "  input_shape = (row, column, 3)\n",
        "\n",
        "  ### Inception model\n",
        "  base_model = applications.InceptionV3(weights='imagenet', include_top=False,  input_shape=(row, column,3))\n",
        "  base_model.trainable = False\n",
        "\n",
        "  add_model = Sequential()\n",
        "  add_model.add(base_model)\n",
        "  add_model.add(GlobalAveragePooling2D())\n",
        "  add_model.add(Dropout(0.5))\n",
        "  #add_model.add(Dense(1024, activation = 'relu'))\n",
        "  #add_model.add(Dense(512, activation = 'relu'))\n",
        "  #add_model.add(Dense(256, activation = 'relu'))\n",
        "  add_model.add(Dense(n_class, activation='softmax'))\n",
        "\n",
        "  model = add_model\n",
        "  model.compile(loss='categorical_crossentropy', optimizer = 'Adam', metrics=['accuracy'])\n",
        "  return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZvR5MBoz2aBb"
      },
      "source": [
        "# *Pre process the textual data*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M0hklnVpHEA4"
      },
      "source": [
        "### Pre process the textual data\n",
        "def preprocess_text(text, stem = True, lem = True, stop_words = set(nltk.corpus.stopwords.words('english'))):\n",
        "    \n",
        "    ### Convert to lowercase, remove characters and punctuation and strip\n",
        "    text = re.sub(r'[^\\w\\s]', '', str(text).lower().strip())\n",
        "    \n",
        "    ### Tokenize\n",
        "    text = text.split()\n",
        "    \n",
        "    ### remove stop words\n",
        "    text = [w for w in text if not w in stop_words] \n",
        "    \n",
        "    ### Stemming\n",
        "    if(stem):\n",
        "        ps = nltk.stem.porter.PorterStemmer()\n",
        "        text = [ps.stem(w) for w in text]\n",
        "    ### Lemmatization\n",
        "    if(lem):\n",
        "        lemat = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "        text = [lemat.lemmatize(w) for w in text]\n",
        "    \n",
        "    ### Join back to text\n",
        "    text = ' '.join(text)\n",
        "    return text\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V507mlzXWjvD"
      },
      "source": [
        "# *Configure and setup the BERT model*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m8MgL8utHGVO"
      },
      "source": [
        "def build_bert_model():\n",
        "\n",
        "  ### Name of the BERT model to use \n",
        "  model_name = 'bert-base-uncased'\n",
        "  ### Max length of tokens\n",
        "  max_length = 256\n",
        "\n",
        "  ### Load transformers config and set output_hidden_states to False\n",
        "  config = BertConfig.from_pretrained(model_name)\n",
        "  config.output_hidden_states = False\n",
        "\n",
        "  ### Load BERT tokenizer\n",
        "  tokenizer = BertTokenizerFast.from_pretrained(pretrained_model_name_or_path = model_name, config = config)\n",
        "\n",
        "  ### Load the Transformers BERT model\n",
        "  transformer_model = TFBertModel.from_pretrained(model_name, config = config)\n",
        "\n",
        "  ### Load the MainLayer\n",
        "  bert = transformer_model.layers[0]\n",
        "  bert.trainable = False\n",
        "  ### Input layer\n",
        "  input = Input(shape=(max_length,), dtype='int32')\n",
        "  ### Load the Transformers BERT model as a layer in a Keras model\n",
        "  bert_layer = bert(input)[1]\n",
        "  x = Dropout(config.hidden_dropout_prob)(bert_layer)\n",
        "  x = Dense(units = 32, activation = 'relu')(x)\n",
        "  x = Dense(units = 64, activation = 'relu')(x)\n",
        "  x = Dense(units = 128, activation = 'relu')(x)\n",
        "  x = Dense(units = 256, activation = 'relu')(x)\n",
        "  x = Dense(units = 512, activation = 'relu')(x)\n",
        "  #x = Dense(units = 16, activation = 'relu')(x)\n",
        "  output = Dense(units = 3, activation = 'softmax')(x)\n",
        "\n",
        "  model = Model(inputs=input, outputs=output)\n",
        "  model.compile(loss='categorical_crossentropy', optimizer = 'Adam', metrics=['accuracy'])\n",
        "  return model, tokenizer"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EcDP9qfQW5f5"
      },
      "source": [
        "# *BERT tokenizer*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZGyfywzzMcj"
      },
      "source": [
        "### Model building\n",
        "def bert_tokenizer(data, tokenizer):\n",
        "    \n",
        "    tokens = tokenizer(\n",
        "    text = data,\n",
        "    add_special_tokens=True,\n",
        "    max_length = 256,\n",
        "    truncation=True,\n",
        "    padding=True, \n",
        "    return_tensors='tf',\n",
        "    return_token_type_ids = False,\n",
        "    return_attention_mask = False,\n",
        "    verbose = True)\n",
        "\n",
        "    return tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1__QjKl0g1gG"
      },
      "source": [
        "# *Train the model (Image classification)*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZumSrUZZkln"
      },
      "source": [
        "def train_image_model():\n",
        "  path = \"/content/drive/My Drive/data\"\n",
        "  x_train = generate_data(50, path + \"/train\")\n",
        "  x_val = generate_data(50, path + \"/validation\")\n",
        "\n",
        "  image_model = image_model(360, 360, 3)\n",
        "  image_model.fit_generator(\n",
        "    x_train,\n",
        "    epochs = 2,\n",
        "    validation_data = x_val,   \n",
        "    validation_steps = 1\n",
        "    )\n",
        "\n",
        "  # save entire model to HDF5 \n",
        "  image_model.save(\"video.h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qFDDshUxszV7"
      },
      "source": [
        "# *Preapre the data for text classification*"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_DW1morUgfHr"
      },
      "source": [
        "def text_prepare_build(categories):\n",
        "  data = []\n",
        "  classes = []\n",
        "  translator = Translator()\n",
        "\n",
        "  path = \"/content/drive/My Drive/data\"\n",
        "\n",
        "  for file_name in os.listdir(path):\n",
        "    if(file_name.find('.txt') != -1):\n",
        "      with open(path + '/' + file_name, 'r') as f:\n",
        "        obj = json.loads(f.read())\n",
        "        ### Check if there is any audio\n",
        "        if(obj[\"audio\"] != \"\"):\n",
        "            \n",
        "            temp = obj[\"audio\"]\n",
        "            temp = temp.split('.')\n",
        "            text = []\n",
        "\n",
        "            ### Check if the language is english\n",
        "\n",
        "            if(obj[\"language\"] == \"en\"):\n",
        "              text = [preprocess_text(i) for i in temp]\n",
        "            else:\n",
        "              ### Otherwise translate\n",
        "              for sentence in temp:\n",
        "                if(len(sentence) > 1):\n",
        "                  text.append(translator.translate(sentence, src = 'hi').text)\n",
        "              [preprocess_text(i) for i in text]\n",
        "\n",
        "            for i in range(0,len(text)):\n",
        "              classes.append(file_name[:file_name.find('_')])\n",
        "            data.append(text)         \n",
        "\n",
        "  ### Concatenate the lists and create the labels\n",
        "  data = [sentence for sublist in data for sentence in sublist]\n",
        "  classes = [categories.index(i) for i in classes]\n",
        "\n",
        "  #classes = to_categorical(classes)\n",
        "\n",
        "  x_train, x_val, y_train, y_val = train_test_split(data, classes, test_size = 0.1)\n",
        "\n",
        "  #bert_model, tokenizer = build_bert_model()\n",
        "\n",
        "  #x_train = bert_tokenizer(x_train, tokenizer)\n",
        "  #x_val = bert_tokenizer(x_val, tokenizer)\n",
        "\n",
        "  #bert_model.fit(\n",
        "  #   x =  x_train['input_ids'], \n",
        "  #   y = y_train, \n",
        "  #   epochs = 25,\n",
        "  #   batch_size = 16,\n",
        "  #   validation_data = (x_val['input_ids'], y_val)\n",
        "  #)\n",
        "\n",
        "  ### Use TF-IDF vectorization\n",
        "\n",
        "  tfidf_vectorizer = TfidfVectorizer(max_df=0.7)\n",
        "  tfidf_train = tfidf_vectorizer.fit_transform(x_train) \n",
        "  tfidf_val = tfidf_vectorizer.transform(x_val)\n",
        "\n",
        "  return tfidf_train, y_train, tfidf_val, y_val\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bc3_dNWSbOch"
      },
      "source": [
        "# Function to transform the label data into one against many"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TqbjdjfbWxG"
      },
      "source": [
        "def create_one_label(y_train, y_val, class_id):\n",
        "    new_y_train = []\n",
        "    new_y_val = []\n",
        "    for i in range(0, len(y_train)):\n",
        "      if(y_train[i] != class_id):\n",
        "        new_y_train.append(0)\n",
        "      else:\n",
        "        new_y_train.append(1)\n",
        "    for i in range(0, len(y_val)):\n",
        "      if(y_val[i] != class_id):\n",
        "        new_y_val.append(0)\n",
        "      else:\n",
        "        new_y_val.append(1)\n",
        "\n",
        "    return new_y_train, new_y_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wlZr2e6ybhnW"
      },
      "source": [
        "# SVM train models for all the classes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DS5Maj1buIT"
      },
      "source": [
        "\n",
        "def svm_models(categories):\n",
        "\n",
        "    x_train, y_train, x_val, y_val = text_prepare(categories)\n",
        "    \n",
        "    for i in range(len(categories)):\n",
        "      yc_train, yc_val = create_one_label(y_train, y_val, i)\n",
        "      svm_classifier = SVC(kernel='rbf')\n",
        "      svm_classifier.fit(x_train,yc_train)\n",
        "      \n",
        "      filename = categories[i] + '.sav'\n",
        "      joblib.dump(svm_classifier, filename)\n",
        "      \n",
        "      #y_pred = svm_classifier.predict(x_val)\n",
        "      #score=accuracy_score(yc_val, y_pred)\n",
        "      #print(f'Accuracy: {round(score*100,2)}%')\n",
        "\n",
        "svm_models(categories)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9x2FNh1CfqVf"
      },
      "source": [
        "# Test new data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GRjDHKPHgn0S"
      },
      "source": [
        "def test():\n",
        "    url = input(\"Enter the url of YouTube video\")\n",
        "    path = \"/content/drive/My drive/data/test\"\n",
        "    name = input(\"Enter name to be saved as\")\n",
        "    categories = ['Technology', 'Healthcare', 'Entertainment']\n",
        "    generate_min_data(path, url, name)\n",
        "    vid = cv2.VideoCapture(path + '/' + name +  \".mp4\")\n",
        "    text = []\n",
        "    with open(path + '/' + file_name, 'r') as f:\n",
        "        obj = json.loads(f.read())\n",
        "        ### Check if there is any audio\n",
        "        if(obj[\"audio\"] != \"\"):\n",
        "            \n",
        "            temp = obj[\"audio\"]\n",
        "            temp = temp.split('.')\n",
        "\n",
        "            ### Check if the language is english\n",
        "\n",
        "            if(obj[\"language\"] == \"en\"):\n",
        "              text = [preprocess_text(i) for i in temp]\n",
        "            else:\n",
        "              ### Otherwise translate\n",
        "              for sentence in temp:\n",
        "                if(len(sentence) > 1):\n",
        "                  text.append(translator.translate(sentence, src = 'hi').text)\n",
        "              [preprocess_text(i) for i in text]\n",
        "\n",
        "    text_score = -1\n",
        "    if text:\n",
        "      \n",
        "      predicitions = []\n",
        "      for i in categories:\n",
        "        classifier = (joblib.load(i + '.sav'))\n",
        "        tfidf_vectorizer = TfidfVectorizer(max_df=0.7)\n",
        "        x_test = tfidf_vectorizer.fit_transform(text) \n",
        "        predictions.append(classifier.predict(x_test))\n",
        "\n",
        "      test_score = max(predictions)\n",
        "      print('text classification:', categories[int(test_score)])\n",
        "\n",
        "    frame_rate = 60\n",
        "    frame_path = path + '/frame'\n",
        "    frames = video_to_frames(path, frame_path, name, frame_path + '/' + name, frame_rate)\n",
        "    x_test = generate_data(frame_rate, frame_path +'/' +name)\n",
        "    model.load('/content/drive/My Drive/data/video.h5')\n",
        "    predicitions = model.predict(x_test)\n",
        "    res = []\n",
        "    for i in range(len(categories)):\n",
        "      res.append(predicitions.count(i))\n",
        "\n",
        "    print('Image classification:', categories[res.index(max(res))])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hu-8Z9V7ZnS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}